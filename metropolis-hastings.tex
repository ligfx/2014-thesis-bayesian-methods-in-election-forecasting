\documentclass[thesis.tex]{subfiles}
\begin{document}


\section{The Metropolis-Hastings algorithm}

Suppose we want to sample from the probability distribution \[
  p(\theta) = k\cdot f(\theta),
\] where K is some unknown normalizing constant.

We first present the \textbf{Metropolis} algorithm. Start with \[
  \theta^{(0)} : f(\theta^{(0)}) > 0.
\] Let \(q(\theta^{(1)} \to \theta^{(2)})\) be a \term{jumping distribution} (or \term{proposal}, or \term{candidate-generating} distibution) which is symmetric, \(q(\theta_1 \to \theta_2) = q(\theta_2 \to \theta_1)\). Then:

\begin{enumerate}
\item Sample a candidate point \(\theta^*\) from \(q\), which denotes the probability of returning \(\theta_2\) given a previous value of \(\theta_1\);

\item Calculate the ratio of density, \[
  \alpha = \frac{p(\theta^*)}{p(\theta^{(t-1)})} = \frac{f(\theta^*)}{f(\theta^{(t-1)})},
\] where the normalizing constant \(k\) cancels out;

\item If \(\theta^*\) increases the density (\(\alpha > 1\)), then accept the candidate and set \(\theta^{(t)} = \theta^*\). Otherwise, then accept the candidate with probability \(\alpha\), or pick a new candidate and try again.

\end{enumerate}

Another way to look at it is, accept a candidate with probability \[
  \alpha = \min\left[ \frac{f(\theta^*)}{f(\theta^{(t-1)})},\, 1 \right].
\]

The \term{Metropolis-Hastings} algorithm extends the above to work in the case where \(q(\theta_1 \to \theta_2)\) is any distribution, symmetric or not. Let the density ratio be \[
  \alpha = \min \left[ \frac{f(\theta^*)}{f(\theta^{(t-1)})}\frac{q(\theta^* \to \theta^{(t-1)})}{q(\theta^{(t-1)} \to \theta^*)},\, 1 \right].
\] In the case where \(q\) is symmetric, this becomes simply Metropolis.

\bigskip

\noindent\textbf{Claim:} Metropolis-Hastings generates a Markov chain whose stationary distribution is \(p\). We show it satisfies the detailed balance equation. Since we sample from \(q(\theta_1 \to \theta_2)\), and accept with probability \(\alpha(\theta_1, \theta_2)\), \[
  \Pr(\theta_1 \to \theta_2) = q(\theta_1 \to \theta_2)  \alpha(\theta_1, \theta_2) = q(\theta_1 \to \theta_2) \min \left[\frac{p(\theta_2)}{p(\theta_1)}\frac{q(\theta_2 \to \theta_1)}{q(\theta_1 \to \theta_2)} ,\, 1\right].
\] We want to show that \[
  \Pr(\theta_1 \to \theta_2) p(\theta_1) = \Pr(\theta_2 \to \theta_1)p(\theta_2),
\] or \[
  q(\theta_1 \to \theta_2)\alpha(\theta_1, \theta_2) p(\theta_1) = q(\theta_2 \to \theta_1) \alpha(\theta_2, \theta_1) p(\theta_2).
\] Assume without loss of generality that \(\alpha(\theta_1, \theta_2) < 1\). Then terms cancel and we see the equality.

\bigskip

\noindent\textbf{Example:} Consider the scaled inverse-\(\chi^2\) distribution, \[
  p(\theta) = C \cdot \theta^{-n/2} \cdot \exp \left(-\frac{a}{2\theta}\right),
\] with degrees of freedom \(n = 5\), and scaling factor \(a = 4\).

Take a Metropolis candidate distribution, the uniform distribution from 0 to 100. We know \(p\) has tails outside this range, but assume that they're negligible.

Now, run the Metropolis algorithm: Let \(\theta^{(0)} = 1\), and suppose \(\theta^* = 39.82\). Then \[
  \alpha = \min\left[ \frac{p(\theta^*)}{p(\theta^{(t-1)})} ,\, 1\right] = \min\left[ \frac{(\theta^*)^{-5/2} \exp\left( -\frac{2}{\theta^*} \right)}{(\theta^{(t-1)})^{-5/2} \exp\left( -\frac{2}{\theta^{(t-1)}} \right)},\, 1 \right] = 0.0007,
\] so we accept \(\theta^*\) with probability 0.0007.

\begin{comment}
Plot of first 500 values shows long flat periods---this is called \term{poorly-mixing}. TODO

In contrast, suppose we use \(\chi^2(1)\) as the proposal distribution. This no longer meets the assumptions of Metroplis (\(q(\theta_2) \ne q(\theta_1)\)), so we use Metropolis-Hastings. Now the plot looks morel ike white noise, and we say that it is \term{well-mixing}. TODO
\end{comment}

\end{document}

\begin{comment}

The Metropolis-Hastings algorithm is a technique in the family of Markov-Chain Monte Carlo (MCMC) methods that allows numerically approximating a probability distribution, often used when the distribution is difficult to sample from directly.

The algorithm generates sequences of samples in such a way that their distribution converges to the actual distribution being analyzed. Each sample is dependent only on the sample before it, making the sequence a Markov chain.

The Metropolis-Hastings algorithm works as follows, given a stationary distribution with PDF $f$ (the distribution to sample from) and a proposal distribution $g$:

\begin{enumerate}
  \item Given $X_t = x$ at time $t$
  \item Sample $y$ from the proposal distribution with $g(y|X_t = x)$
  \item Calculate the Metropolis-Hastings ratio: \[
    R(x, y) = \min\left( \dfrac{f(y)g(x|y)}{f(x)g(y|x)}, 1 \right)
  \]
  and with probability $R(x, y)$, let $X_{t+1} = y$. Otherwise let $X_{t+1} = X_t$.
\end{enumerate}

This algorithm produces a sequence of samples whose distribution converges to $f$.

Let $x_1$ and $x_2$ be two possible values of the proposal distribution. Suppose $f(x_1)g(x_2|x_1) < f(x_2)g(x_1|x_2)$. Then the transition from $x_1$ to $x_2$ has joint distribution the change of starting with $x_1$ and being offered $x_2$, multiplied by the M-H ratio: or, in other words $f(x_1)g(x_2|x_1)$. The transition the other way has a joint distribution of \[ f(x_2)g(x_2|x_1)\dfrac{f(x_1)g(x_2|x_1)}{f(x_2)g(x_1|x_2)} = f(x_1)g(x_2|x_1)\]
and thus by the statements on Markov chains above this chain is reversible and $f$ is its stationary distribution.

%% TODO: Wow that's weird to understand. Specifically the bit about reversibility and how to prove that.

%% TODO: Need more about how to pick a proposal distribution.

\end{comment}